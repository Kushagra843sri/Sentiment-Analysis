{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a128d361-7f62-415d-ad6e-d874fba59df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wordcloud) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wordcloud) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.2 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.2 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 20.5/300.2 kB 165.2 kB/s eta 0:00:02\n",
      "   --- ----------------------------------- 30.7/300.2 kB 187.9 kB/s eta 0:00:02\n",
      "   ---------- ---------------------------- 81.9/300.2 kB 383.3 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/300.2 kB 655.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  297.0/300.2 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 300.2/300.2 kB 929.2 kB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08aff0a1-e49f-4dc0-bf8e-d6cd4b791e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686c4c70-c54b-4830-ada1-129f3fd6ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # importing our dataset\n",
    "conversation =\"WhatsApp Chat with Yashi.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf66950-a8cc-4d14-84d8-eb7c5715f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will find time \n",
    "def date_time(s):\n",
    "    pattern = r'^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+),([0-9]+)\\s?(AM|PM|am|pm)?-'\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed7915f4-7019-4622-a385-d26133162b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finding the authors\n",
    "\n",
    "def find_author(s):\n",
    "    s = s.split(\":\")\n",
    "    if len(s) == 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22a52c39-dd2a-4b6b-87c6-abc25f85543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will extraxt messages\n",
    "\n",
    "def messages(line):\n",
    "    splitline = line.split(' - ')\n",
    "    dateTime = splitline[0]\n",
    "    date,Time = dateTime.split(\",\")\n",
    "    message=\" \".join(splitline[1:])\n",
    "\n",
    "    # now finding message belongs to which author\n",
    "    if find_author(message):\n",
    "        splitmessage = message.split(\":\")\n",
    "        author = splitmessage[0]\n",
    "        message=\" \".join(splitmessage[1])\n",
    "    else:\n",
    "        author=None\n",
    "\n",
    "    return date, Time, author, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eec07bc-c5cd-4e84-87dc-9de526c02429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing our dataset now\n",
    "\n",
    "data = []\n",
    "\n",
    "conversation=\"WhatsApp Chat with Yashi.txt\"\n",
    "\n",
    "with open(conversation, encoding='utf-8') as fp:\n",
    "    fp.readline()\n",
    "    messageBuffer = []\n",
    "    date, Time, author = None, None, None\n",
    "\n",
    "    while True:\n",
    "        line=fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if date_time(line):\n",
    "            if len(messageBuffer) > 0:\n",
    "                date.append([date, Time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear()\n",
    "            date, Time, author, message = messages(line)\n",
    "            messageBuffer.append(message)\n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2d780e6-1b4a-4420-ac69-803f46af0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea945811-6acf-4b83-b8ae-d717e06e1c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Time, Author, Message, Positive, Negative, Neutral]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# now we will Train our dataset\n",
    "# we will use sentiment intensity analyzer algorithm(SIAA), it is a part of NLTK VADER module which label dataset as positive or negative\n",
    "# we use polarity score method to determine sentiment\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Date\",\"Time\",\"Author\",\"Message\"])\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "data = df.dropna()\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "data[\"Positive\"] = [sentiments.polarity_score(i)['pos'] for i in data[\"Message\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_score(i)['neg'] for i in data[\"Message\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_score(i)['neu'] for i in data[\"Message\"]]\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec57c9a-f4ab-4e7e-ac6c-a27b74f7eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# validating our data\n",
    "\n",
    "x = sum(data['Positive'])\n",
    "y = sum(data['Negative'])\n",
    "z = sum(data['Neutral'])\n",
    "\n",
    "def score(a,b,c):\n",
    "    if(a>b) and (a>c):\n",
    "        print(\"Positive\")\n",
    "    elif(b>a) and (b>c):\n",
    "        print(\"Negative\")\n",
    "    else:\n",
    "        print(\"Neutral\")\n",
    "\n",
    "score(x,y,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7bb3a-cbf2-4e4f-995d-e899b1742330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can see that the result is neutral i.e our whatsapp chat sentiment is neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06baa1-a963-47c2-9783-79cfca90a8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0003b4-4c30-4d30-854c-86c47fe6784a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
